{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of Chessboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import line_and_point_detect as lp\n",
    "\n",
    "def show_img(img):\n",
    "    # convert color from CV2 BGR back to RGB\n",
    "    image = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    display(Image.fromarray(image))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"Chessboard_00451_2.png\" # sin\n",
    "# filename = \"Chessboard_00451.png\" # normal\n",
    "filename = \"Chessboard_0481_0.png\" # noise\n",
    "# filename = \"Chessboard_0481.png\"\n",
    "# filename = \"Chessboard_0511.png\"\n",
    "# filename = \"Chessboard_0541.png\"\n",
    "# filename = \"Chessboard_00601.png\"\n",
    "# filename = \"Chessboard0631.png\"\n",
    "\n",
    "img = cv.imread(filename)\n",
    "show_img(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    " \n",
    "### Convert the image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "show_img(gray)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove sinusoidal noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_color(img):\n",
    "    # get the average color of the image\n",
    "    return np.sum(img) / (np.shape(img)[0] * np.shape(img)[1])\n",
    "\n",
    "def remove_sinusoidal_noise(img):\n",
    "    # Convert the image to a 2D numpy array\n",
    "    img = np.array(img)\n",
    "\n",
    "    # Apply the FFT to the image\n",
    "    f = np.fft.fft2(img)\n",
    "\n",
    "    # Shift the zero-frequency component to the center\n",
    "    fshift = np.fft.fftshift(f)\n",
    "\n",
    "    # To see if components were removed\n",
    "    removed = False\n",
    "\n",
    "    # Get the rows and columns of the image\n",
    "    rows, cols = img.shape\n",
    "\n",
    "    # Set the noise-removal threshold for the other frequency components\n",
    "    other_freq_threshold = 1000 * average_color(np.abs(fshift))\n",
    "\n",
    "    # Zero out the high-frequency components that correspond to noise\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            if not (y == rows // 2 and x == cols // 2):\n",
    "                if np.abs(fshift[y][x]) > other_freq_threshold:\n",
    "                    fshift[y][x] = 0\n",
    "                    removed = True\n",
    "\n",
    "    # Shift the zero-frequency component back to the original location\n",
    "    f_ishift = np.fft.ifftshift(fshift)\n",
    "\n",
    "    # Apply the inverse FFT to the filtered image\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "\n",
    "    # Convert the result back to an 8-bit unsigned integer\n",
    "    img_back = np.abs(img_back).astype(np.uint8)\n",
    "    return [img_back, removed]\n",
    "\n",
    "\n",
    "\n",
    "img_nosin, is_sin_removed = remove_sinusoidal_noise(gray)\n",
    "show_img(img_nosin)\n",
    "\n",
    "if is_sin_removed:\n",
    "    gray = img_nosin\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian of Gaussian\n",
    "#### Apply Gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian = cv.GaussianBlur(gray, (3, 3), 0)\n",
    "gaussian = cv.GaussianBlur(gray, (15, 15), 0)\n",
    "\n",
    "show_img(gaussian)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply [Laplacian of Gaussian filter](https://docs.opencv.org/3.4/d5/db5/tutorial_laplace_operator.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = cv.Laplacian(gaussian, cv.CV_8U, ksize=5)\n",
    "\n",
    "show_img(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the gaussian blurr and the log edges.\n",
    "\n",
    "The weight is ranging from 0 to 1. A value of 1 means the image will be fully visible in the output, while a value of 0 means it will be fully transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv.addWeighted(gaussian, 1, log, 0.5, 0)\n",
    "show_img(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv.Canny(result, 70, 120)\n",
    "show_img(canny)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_tab = []\n",
    "line_tab = lp.lines_detector(canny, 120)\n",
    "show_img(lp.draw_lines(img, line_tab)) # Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_tabP = lp.lines_detector_P(canny, 50, 100, 150)\n",
    "show_img(lp.draw_lines(img, line_tabP)) # LinesP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersectP = lp.find_all_intersection(img, line_tabP)\n",
    "img2 = np.copy(img)\n",
    "#\n",
    "\n",
    "for point in intersectP:\n",
    "    cv.circle(img2, (int(point[0]), int(point[1])), 5, (0, 255, 0), 3)\n",
    "\n",
    "show_img(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(intersectP), len(line_tab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51fe7af6622775b13855002464e5e74330b8a28b85f6a4277822c429d55419ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
